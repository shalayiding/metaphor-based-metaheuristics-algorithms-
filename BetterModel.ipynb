{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hailthedawn/BISFinalProject/blob/main/BetterModel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JjRPFVnCJOUh",
        "outputId": "32cd695f-bbc1-4c25-f753-648a3a31aed5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pathlib2\n",
            "  Downloading pathlib2-2.3.7.post1-py2.py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from pathlib2) (1.15.0)\n",
            "Installing collected packages: pathlib2\n",
            "Successfully installed pathlib2-2.3.7.post1\n"
          ]
        }
      ],
      "source": [
        "pip install pathlib2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZaGb5K3kJOUh"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import glob\n",
        "import tensorflow_datasets as tfds\n",
        "from tensorflow.io import FixedLenFeature, parse_single_example\n",
        "#from librosa.core.time_frequency import mel_frequencies\n",
        "from pathlib2 import Path\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy import signal\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "En7w0SVVJOUj"
      },
      "source": [
        "### Download or load dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m_U_VfD3JOUj",
        "outputId": "821540af-54b8-4c6e-f553-4c7edd4b6db4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PosixPath('/content/data')"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "DATA_DIR = Path(\"data\").resolve()\n",
        "DATA_DIR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 214,
          "referenced_widgets": [
            "742f4f122f5f4f10a23215d5ba3737ed",
            "f59ee8661d1443a69542e1ea9228ddce",
            "2509d8dac0474de0999080ab3e508f58",
            "afd8e69a68a54fbb83e2e728a3fd51f8",
            "41a37971fb8f4af899ee50e4a4adc990",
            "aa7ebb2f2e7e4a8f9851f4af8f2908ee",
            "c4dff697b5cf461aada3f9d5fbf5e322",
            "b3bd27da718c44b7b7dcd71584e9eb29",
            "eabcf23b319741c480907733ef04df87",
            "88c8bb58f94741b089cd1084ae326fcc",
            "25aef006745d409e8e862e7040f3830d"
          ]
        },
        "id": "fcezGuLMJOUk",
        "outputId": "b5f12890-60d4-4bbd-d384-17a9ded70584"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mDownloading and preparing dataset nsynth/full/2.3.3 (download: 73.07 GiB, generated: 73.09 GiB, total: 146.16 GiB) to /content/data/nsynth/full/2.3.3...\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Dataset nsynth is hosted on GCS. It will automatically be downloaded to your\n",
            "local data directory. If you'd instead prefer to read directly from our public\n",
            "GCS bucket (recommended if you're running on GCP), you can instead pass\n",
            "`try_gcs=True` to `tfds.load` or set `data_dir=gs://tfds-data/datasets`.\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Dl Completed...:   0%|          | 0/1069 [00:00<?, ? file/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "742f4f122f5f4f10a23215d5ba3737ed"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\u001b[1mDataset nsynth downloaded and prepared to /content/data/nsynth/full/2.3.3. Subsequent calls will reuse this data.\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "ds_train, ds_test = tfds.load(\n",
        "    name=\"nsynth\", split=[\"train\", \"test\"], data_dir=DATA_DIR\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nusrIR3yJOUq"
      },
      "source": [
        "### Produce the datasets from tfrecords"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IcjDmd7mJOUq"
      },
      "outputs": [],
      "source": [
        "training_tfrecords = [str(i) for i in list((DATA_DIR / \"nsynth\").glob('**/*train.tfrecord*'))]\n",
        "raw_dataset = tf.data.TFRecordDataset(training_tfrecords)\n",
        "\n",
        "val_tfrecords = [str(i) for i in list((DATA_DIR / \"nsynth\").glob('**/*valid.tfrecord*'))]\n",
        "val_dataset = tf.data.TFRecordDataset(val_tfrecords)\n",
        "\n",
        "test_tfrecords = [str(i) for i in list((DATA_DIR / \"nsynth\").glob('**/*test.tfrecord*'))]\n",
        "test_dataset = tf.data.TFRecordDataset(test_tfrecords)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zUrNQBqY_R1K"
      },
      "source": [
        "**Function to label classes from ints**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nhHqvqADBlG5"
      },
      "outputs": [],
      "source": [
        "\n",
        "def label_instrument(num):\n",
        "  if num == 0:\n",
        "    return \"bass\"\n",
        "  if num == 1:\n",
        "    return \"brass\"\n",
        "  if num == 2:\n",
        "    return \"flute\"\n",
        "  if num == 3:\n",
        "    return \"guitar\"\n",
        "  if num == 4:\n",
        "    return \"keyboard\"\n",
        "  if num == 5:\n",
        "    return \"mallet\"\n",
        "  if num == 6:\n",
        "    return \"organ\"\n",
        "  if num == 7:\n",
        "    return \"reed\"\n",
        "  if num == 8:\n",
        "    return \"string\"\n",
        "  if num == 9:\n",
        "    return \"vocal\"\n",
        "  else:\n",
        "    return \"invalid class\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6X0VSYLiKul5"
      },
      "source": [
        "BETTER NETWORK"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jpBmuiHlNDZp"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import Input, Dense, Conv1D, Activation, Dropout, MaxPooling1D, Flatten, LSTM, Bidirectional\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras import optimizers\n",
        "from scipy import signal"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VQKN7usE_Xkj"
      },
      "source": [
        "**READ IN TRAINING DATA**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vTiDMcPVOHTt"
      },
      "outputs": [],
      "source": [
        "#raw_dataset = raw_dataset\n",
        "X=[]\n",
        "y=[]\n",
        "counts = dict()\n",
        "#names=[]\n",
        "counter=0\n",
        "with tf.device('/device:GPU:0'):\n",
        "  for raw_record in raw_dataset.take(50000):\n",
        "     example = tf.train.Example()\n",
        "     example.ParseFromString(raw_record.numpy())\n",
        "     #print(example)\n",
        "     temp=example.features.feature[\"instrument/family\"].int64_list.value[0]\n",
        "     #print(temp)\n",
        "     if(temp!=9):          \n",
        "       if(counts.get(temp)==None or counts.get(temp)<4000):\n",
        "          X.append(example.features.feature[\"audio\"].float_list.value[:16000])\n",
        "          y.append(example.features.feature[\"instrument/family\"].int64_list.value[0])\n",
        "          \n",
        "          counts[temp] = counts.get(temp, 0) + 1\n",
        "       if counts.get(temp)>4000:\n",
        "          break\n",
        "              \n",
        "\n",
        "\n",
        "yClass=[]\n",
        "\n",
        "for i in range(0,len(y)):\n",
        "    temp=[0] * 11\n",
        "    temp[y[i]]=1\n",
        "    yClass.append(temp)\n",
        "yTrain=np.array(yClass)\n",
        "counter=0\n",
        "\n",
        "XTrain= np.array(X)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6RNYydtIJdUH",
        "outputId": "13e55a1d-f320-456f-de54-9e6b49a2ffb6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(9886, 160, 100)"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ioMOkOZb_eRR"
      },
      "source": [
        "**NEXT READ IN VAL DATA**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KCLQDbBlXRpA"
      },
      "outputs": [],
      "source": [
        "X=[]\n",
        "y=[]\n",
        "counts = dict()\n",
        "#names=[]\n",
        "counter=0\n",
        "for raw_record in val_dataset.take(3500):\n",
        "     example = tf.train.Example()\n",
        "     example.ParseFromString(raw_record.numpy())\n",
        "     #print(example)\n",
        "     temp=example.features.feature[\"instrument/family\"].int64_list.value[0]\n",
        "     #print(temp)\n",
        "     #print(temp)\n",
        "     if(temp!=9):          \n",
        "       if(counts.get(temp)==None or counts.get(temp)<1000):\n",
        "          X.append([example.features.feature[\"audio\"].float_list.value[:16000]])\n",
        "          y.append(example.features.feature[\"instrument/family\"].int64_list.value[0])\n",
        "          \n",
        "          counts[temp] = counts.get(temp, 0) + 1\n",
        "         \n",
        "#print(y)\n",
        "yClass=[]\n",
        "#counts=None\n",
        "for i in range(0,len(y)):\n",
        "    temp=[0] * 11\n",
        "    temp[y[i]]=1\n",
        "    yClass.append(temp)\n",
        "yVal=np.array(yClass)\n",
        "#yVal=np.array(y)\n",
        "Xnew=[]\n",
        "counter=0\n",
        "for i in  X:\n",
        "    #counter=1+counter\n",
        "    Xnew.append(i)\n",
        "XVal= np.array(Xnew)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0_9JioynJ6c-"
      },
      "outputs": [],
      "source": [
        "XTrain = XTrain.reshape(XTrain.shape[0], 160, 100)\n",
        "XVal = XVal.reshape(XVal.shape[0], 160, 100)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QmklyaZG_lfg"
      },
      "source": [
        "**1D Convolutional Model**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FVdKN4ya_qeh"
      },
      "source": [
        "**Train Function**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zB2P6TVdHIpQ"
      },
      "source": [
        "**LSTM model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2yh2QAgqHAdj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "93111082-d452-47cd-8dde-912a864e476f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Layer lstm_64 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_64 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "model = Sequential()\n",
        "model.add(LSTM(128, input_shape=( 160, 100), recurrent_dropout=0.2))\n",
        "# model.add(LSTM(256, return_sequences=True))\n",
        "# model.add(LSTM(128, return_sequences=False))\n",
        "model.add(Dense( 256, activation='relu'))\n",
        "model.add(Dense(11, activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer=optimizers.Adam(), metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dFK8Vp4DV5Qu"
      },
      "outputs": [],
      "source": [
        "with tf.device('/device:GPU:0'):\n",
        "  history_lstm = model.fit(XTrain, yTrain, validation_data=(XVal,yVal),epochs=20, batch_size=2000)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "forward_layer = LSTM(100, return_sequences=True, recurrent_dropout=0.2)\n",
        "backward_layer = LSTM(100, activation='relu', return_sequences=True,\n",
        "                       go_backwards=True, recurrent_dropout=0.2)\n",
        "model.add(Bidirectional(forward_layer, backward_layer=backward_layer,\n",
        "                         input_shape=(160, 100)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense( 512, activation='relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense( 256, activation='relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense( 128, activation='relu'))\n",
        "model.add(Dense(11, activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SR0fnbKzlitM",
        "outputId": "0976f1c6-b1ef-445b-9e19-5fbecdad101b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# with tf.device('/device:GPU:0'):\n",
        "history_lstm = model.fit(XTrain, yTrain, validation_data=(XVal,yVal),epochs=30, batch_size=1000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pknRayKil08z",
        "outputId": "56cbae5d-66d4-4ed5-e8d2-e5a83a24f7cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "32/32 [==============================] - 39s 993ms/step - loss: 2.0435 - accuracy: 0.2487 - val_loss: 1.6671 - val_accuracy: 0.3277\n",
            "Epoch 2/30\n",
            "32/32 [==============================] - 31s 985ms/step - loss: 1.6938 - accuracy: 0.3789 - val_loss: 1.5699 - val_accuracy: 0.3909\n",
            "Epoch 3/30\n",
            "32/32 [==============================] - 31s 981ms/step - loss: 1.5020 - accuracy: 0.4456 - val_loss: 1.5887 - val_accuracy: 0.3866\n",
            "Epoch 4/30\n",
            "32/32 [==============================] - 31s 971ms/step - loss: 1.3566 - accuracy: 0.5009 - val_loss: 1.5671 - val_accuracy: 0.4177\n",
            "Epoch 5/30\n",
            "32/32 [==============================] - 31s 980ms/step - loss: 1.2248 - accuracy: 0.5537 - val_loss: 1.6320 - val_accuracy: 0.4263\n",
            "Epoch 6/30\n",
            "32/32 [==============================] - 31s 984ms/step - loss: 1.0895 - accuracy: 0.6057 - val_loss: 1.6174 - val_accuracy: 0.4634\n",
            "Epoch 7/30\n",
            "32/32 [==============================] - 31s 982ms/step - loss: 0.9645 - accuracy: 0.6520 - val_loss: 1.6366 - val_accuracy: 0.4700\n",
            "Epoch 8/30\n",
            "32/32 [==============================] - 32s 985ms/step - loss: 0.8304 - accuracy: 0.7028 - val_loss: 1.7043 - val_accuracy: 0.4863\n",
            "Epoch 9/30\n",
            "32/32 [==============================] - 32s 987ms/step - loss: 0.7067 - accuracy: 0.7471 - val_loss: 1.8214 - val_accuracy: 0.4883\n",
            "Epoch 10/30\n",
            "32/32 [==============================] - 31s 973ms/step - loss: 0.6077 - accuracy: 0.7840 - val_loss: 1.9139 - val_accuracy: 0.4837\n",
            "Epoch 11/30\n",
            "32/32 [==============================] - 31s 985ms/step - loss: 0.5206 - accuracy: 0.8201 - val_loss: 2.1206 - val_accuracy: 0.4886\n",
            "Epoch 12/30\n",
            "32/32 [==============================] - 31s 983ms/step - loss: 0.4565 - accuracy: 0.8427 - val_loss: 2.1136 - val_accuracy: 0.4849\n",
            "Epoch 13/30\n",
            "32/32 [==============================] - 31s 984ms/step - loss: 0.4157 - accuracy: 0.8629 - val_loss: 2.1777 - val_accuracy: 0.5060\n",
            "Epoch 14/30\n",
            "32/32 [==============================] - 32s 985ms/step - loss: 0.3523 - accuracy: 0.8816 - val_loss: 2.2828 - val_accuracy: 0.4994\n",
            "Epoch 15/30\n",
            "32/32 [==============================] - 31s 981ms/step - loss: 0.2998 - accuracy: 0.8990 - val_loss: 2.3191 - val_accuracy: 0.5014\n",
            "Epoch 16/30\n",
            "32/32 [==============================] - 31s 981ms/step - loss: 0.2600 - accuracy: 0.9115 - val_loss: 2.6056 - val_accuracy: 0.4909\n",
            "Epoch 17/30\n",
            "32/32 [==============================] - 31s 980ms/step - loss: 0.2355 - accuracy: 0.9174 - val_loss: 2.6648 - val_accuracy: 0.4920\n",
            "Epoch 18/30\n",
            "32/32 [==============================] - 31s 981ms/step - loss: 0.2118 - accuracy: 0.9285 - val_loss: 2.7011 - val_accuracy: 0.5071\n",
            "Epoch 19/30\n",
            "32/32 [==============================] - 31s 981ms/step - loss: 0.1975 - accuracy: 0.9344 - val_loss: 2.7310 - val_accuracy: 0.5034\n",
            "Epoch 20/30\n",
            "32/32 [==============================] - 31s 982ms/step - loss: 0.1786 - accuracy: 0.9407 - val_loss: 2.9107 - val_accuracy: 0.5003\n",
            "Epoch 21/30\n",
            "32/32 [==============================] - 31s 980ms/step - loss: 0.1680 - accuracy: 0.9440 - val_loss: 2.8548 - val_accuracy: 0.5026\n",
            "Epoch 22/30\n",
            "32/32 [==============================] - 31s 972ms/step - loss: 0.1474 - accuracy: 0.9514 - val_loss: 2.9357 - val_accuracy: 0.4763\n",
            "Epoch 23/30\n",
            "32/32 [==============================] - 31s 983ms/step - loss: 0.1414 - accuracy: 0.9541 - val_loss: 3.1229 - val_accuracy: 0.4920\n",
            "Epoch 24/30\n",
            "32/32 [==============================] - 31s 981ms/step - loss: 0.1241 - accuracy: 0.9581 - val_loss: 3.2068 - val_accuracy: 0.5034\n",
            "Epoch 25/30\n",
            "32/32 [==============================] - 31s 979ms/step - loss: 0.1188 - accuracy: 0.9610 - val_loss: 3.3633 - val_accuracy: 0.4794\n",
            "Epoch 26/30\n",
            "32/32 [==============================] - 32s 988ms/step - loss: 0.1077 - accuracy: 0.9635 - val_loss: 3.3941 - val_accuracy: 0.5023\n",
            "Epoch 27/30\n",
            "32/32 [==============================] - 31s 984ms/step - loss: 0.1073 - accuracy: 0.9638 - val_loss: 3.4974 - val_accuracy: 0.4880\n",
            "Epoch 28/30\n",
            "32/32 [==============================] - 31s 978ms/step - loss: 0.1013 - accuracy: 0.9665 - val_loss: 3.1950 - val_accuracy: 0.5031\n",
            "Epoch 29/30\n",
            "32/32 [==============================] - 31s 979ms/step - loss: 0.1045 - accuracy: 0.9658 - val_loss: 3.4163 - val_accuracy: 0.4946\n",
            "Epoch 30/30\n",
            "32/32 [==============================] - 31s 981ms/step - loss: 0.0976 - accuracy: 0.9663 - val_loss: 3.3355 - val_accuracy: 0.5017\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YoMM3e1S_AkM"
      },
      "source": [
        "TESTING\n",
        "\n",
        "**LOAD IN Xtest and Ytest**\n",
        " - Size of Test Dataset can be changed with the arguement to take()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UcceM2xQavX-"
      },
      "outputs": [],
      "source": [
        "X=[]\n",
        "y=[]\n",
        "counts = dict()\n",
        "#names=[]\n",
        "counter=0\n",
        "for raw_record in test_dataset:\n",
        "     example = tf.train.Example()\n",
        "     example.ParseFromString(raw_record.numpy())\n",
        "\n",
        "     temp=example.features.feature[\"instrument/family\"].int64_list.value[0]   \n",
        "     if(temp!=9):\n",
        " \n",
        "          if(counts.get(temp)==None or counts.get(temp)<1000):\n",
        "            X.append(example.features.feature[\"audio\"].float_list.value[:16000])\n",
        "            y.append(example.features.feature[\"instrument/family\"].int64_list.value[0])\n",
        "          \n",
        "            counts[temp] = counts.get(temp, 0) + 1\n",
        "\n",
        "yClass=[]\n",
        "\n",
        "for i in range(0,len(y)):\n",
        "    temp=[0] * 11\n",
        "    temp[y[i]]=1\n",
        "    yClass.append(temp)\n",
        "yTest=np.array(yClass)\n",
        "#yVal=np.array(y)\n",
        "Xnew=[]\n",
        "counter=0\n",
        "\n",
        "XTest= np.array(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_YyHCo8sbumt",
        "outputId": "0fe2d75f-9460-421d-8595-10ae842b6455"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: BiLSTM-Model/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: BiLSTM-Model/assets\n",
            "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7ef7776cbf10> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
            "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7ef77797add0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
          ]
        }
      ],
      "source": [
        "model.save('BiLSTM-Model')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ebuVQGVp-oE9"
      },
      "source": [
        "**LOAD IN AND TEST THE MODEL**\n",
        "Only the last cell creating XTest and YTest needs to be run.\n",
        "\n",
        "Pass in path to the Better-Model File below"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w1fvu65sSdWZ"
      },
      "outputs": [],
      "source": [
        "model=tf.keras.models.load_model('drive/MyDrive/Better-Model')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rL1AqP7GAjRE"
      },
      "source": [
        "**Evaluate accuracy on test data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rWunjk7BTulR",
        "outputId": "c702de6e-8c4c-40e6-c13a-b425e42c2e05"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "128/128 [==============================] - 12s 85ms/step - loss: 3.1978 - accuracy: 0.5066\n"
          ]
        }
      ],
      "source": [
        "XTest = XTest.reshape(XTest.shape[0], 160, 100)\n",
        "_, accuracy = model.evaluate(XTest, yTest)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "BetterModel.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "742f4f122f5f4f10a23215d5ba3737ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f59ee8661d1443a69542e1ea9228ddce",
              "IPY_MODEL_2509d8dac0474de0999080ab3e508f58",
              "IPY_MODEL_afd8e69a68a54fbb83e2e728a3fd51f8"
            ],
            "layout": "IPY_MODEL_41a37971fb8f4af899ee50e4a4adc990"
          }
        },
        "f59ee8661d1443a69542e1ea9228ddce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aa7ebb2f2e7e4a8f9851f4af8f2908ee",
            "placeholder": "​",
            "style": "IPY_MODEL_c4dff697b5cf461aada3f9d5fbf5e322",
            "value": "Dl Completed...: 100%"
          }
        },
        "2509d8dac0474de0999080ab3e508f58": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b3bd27da718c44b7b7dcd71584e9eb29",
            "max": 1069,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_eabcf23b319741c480907733ef04df87",
            "value": 1069
          }
        },
        "afd8e69a68a54fbb83e2e728a3fd51f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_88c8bb58f94741b089cd1084ae326fcc",
            "placeholder": "​",
            "style": "IPY_MODEL_25aef006745d409e8e862e7040f3830d",
            "value": " 1069/1069 [08:31&lt;00:00,  1.24 file/s]"
          }
        },
        "41a37971fb8f4af899ee50e4a4adc990": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aa7ebb2f2e7e4a8f9851f4af8f2908ee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c4dff697b5cf461aada3f9d5fbf5e322": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b3bd27da718c44b7b7dcd71584e9eb29": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eabcf23b319741c480907733ef04df87": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "88c8bb58f94741b089cd1084ae326fcc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "25aef006745d409e8e862e7040f3830d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}